# Auto Judge  
### Predicting Programming Problem Difficulty

Auto Judge is a machine learningâ€“based system that automatically predicts the **difficulty level** and **difficulty score** of programming problems using only their textual descriptions.

Online coding platforms such as Codeforces, CodeChef, and Kattis usually rely on human judgment and user feedback to label problems as *Easy*, *Medium*, or *Hard*.  
This project demonstrates how **Natural Language Processing (NLP)** and **machine learning** can be used to automate this process.

---

## ğŸ“– Project Objectives

The system predicts:

- **Problem Class** â†’ Easy / Medium / Hard *(Classification)*
- **Problem Score** â†’ Numerical difficulty value *(Regression)*

Predictions are based **only on text**, including:
- Problem description
- Input description
- Output description

No metadata, user submissions, or solution code is used.

---

## ğŸ“‘ Dataset

Each data sample contains:
- `title`
- `description`
- `input_description`
- `output_description`
- `problem_class` (Easy / Medium / Hard)
- `problem_score` (numerical)

The dataset is provided and **no manual labeling is required**.

---

## ğŸ“œ Approach

### 1. Data Preprocessing
- Combined description, input, and output into a single text field
- Cleaned text by removing HTML, URLs, and extra whitespace
- Converted text to lowercase

### 2. Feature Engineering
**Text Features**
- TF-IDF vectors (unigrams + bigrams, max 30,000 features)

**Handcrafted Numeric Features**
- Log-transformed text length
- Log-transformed count of mathematical symbols
- Constraint indicators (constraints, large N, time limits)
- Keyword frequency for algorithm categories:
  - Dynamic Programming
  - Graph Algorithms
  - Data Structures
  - Math
  - Geometry
  - Strings
  - Greedy Techniques

TF-IDF features and numeric features are concatenated to form the final input.

---

## ğŸ—ƒï¸ Models Used

### Classification
- Logistic Regression *(final model)*
- Tried: Random Forest, SVM

### Regression
- Gradient Boosting Regressor *(final model)*
- Tried: Linear Regression, Random Forest

Deep learning was **not used**, as per project guidelines.

---

## ğŸ““ Evaluation Results

### Classification (Logistic Regression)
- **Test Accuracy:** ~54%
- Hard problems were predicted most reliably
- Medium problems were hardest to classify due to overlap

### Regression (Gradient Boosting)
- **Test RMSE:** ~2.01  
- **Test MAE:** ~1.68  

> Note: Gradient Boosting smooths predictions by averaging multiple weak learners, so exact score matching is not expected. Small deviations are normal in NLP-based regression tasks.

---

## ğŸŒ Web Interface (Streamlit)

A simple Streamlit web app allows users to:

1. Paste:
   - Problem description
   - Input description
   - Output description
2. Click **Predict**
3. View:
   - Predicted difficulty class
   - Predicted difficulty score

No authentication or database is required.

---

## ğŸ–¼ï¸ Web Interface Screenshots

![before_1](sample_web_interface_images/before_1.png)
![before_2](sample_web_interface_images/before_2.png)
![after_1](sample_web_interface_images/after_1.png)
![after_2](sample_web_interface_images/after_2.png)


---

## How to Run the Web App (Optional)

```bash
pip install streamlit scikit-learn pandas numpy scipy joblib
streamlit run streamlit_app.py
```

---

## ğŸ“ƒ Project Structure

AutoJudge/
â”‚
â”œâ”€â”€ AutoJudge.ipynb
â”‚   â””â”€â”€ Model training, feature engineering, evaluation, and model saving (Colab)
â”‚
â”œâ”€â”€ streamlit_app.py
â”‚   â””â”€â”€ Streamlit web application for difficulty prediction
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ tfidf.pkl
â”‚   â”œâ”€â”€ logreg_classifier.pkl
â”‚   â”œâ”€â”€ gb_regressor.pkl
â”‚   â””â”€â”€ label_encoder.pkl
â”‚   â””â”€â”€ Saved models and preprocessing objects used by the web app
â”‚
â”œâ”€â”€ sample_web_interface_images/
â”‚   â””â”€â”€ Screenshots of the Streamlit web interface
â”‚
â”œâ”€â”€ data.jsonl
â”‚   â””â”€â”€ Dataset used for training and evaluation
â”‚
â””â”€â”€ README.md
    â””â”€â”€ Project documentation
